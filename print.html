<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The WTy2 Language Specification</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/custom.css">

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Posts</li><li class="chapter-item expanded "><a href="New/green_slime.html"><strong aria-hidden="true">1.</strong> Green Slime</a></li><li class="chapter-item expanded affix "><li class="part-title">WTy2 (Some OLD Ideas Here)</li><li class="chapter-item expanded "><a href="summary/introduction.html"><strong aria-hidden="true">2.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="summary/SUMMARY.html"><strong aria-hidden="true">3.</strong> Basic Concepts</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="basic_concepts/core_types.html"><strong aria-hidden="true">3.1.</strong> Core Types</a></li><li class="chapter-item expanded "><a href="basic_concepts/arrows.html"><strong aria-hidden="true">3.2.</strong> Common Type Operators</a></li><li class="chapter-item expanded "><a href="basic_concepts/functions.html"><strong aria-hidden="true">3.3.</strong> Functions</a></li><li class="chapter-item expanded "><a href="basic_concepts/records.html"><strong aria-hidden="true">3.4.</strong> Records</a></li><li class="chapter-item expanded "><a href="basic_concepts/declarations.html"><strong aria-hidden="true">3.5.</strong> Declarations</a></li><li class="chapter-item expanded "><a href="basic_concepts/erasure_visibility.html"><strong aria-hidden="true">3.6.</strong> Erasure and Visibility</a></li><li class="chapter-item expanded "><a href="basic_concepts/coherence.html"><strong aria-hidden="true">3.7.</strong> Coherence</a></li><li class="chapter-item expanded "><a href="basic_concepts/modules.html"><strong aria-hidden="true">3.8.</strong> Modules</a></li></ol></li><li class="chapter-item expanded "><a href="summary/SUMMARY.html"><strong aria-hidden="true">4.</strong> Extra</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="extra/utilities.html"><strong aria-hidden="true">4.1.</strong> Utilities</a></li></ol></li><li class="chapter-item expanded "><a href="summary/SUMMARY.html"><strong aria-hidden="true">5.</strong> Dependent Types</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="dependent_types/constraints.html"><strong aria-hidden="true">5.1.</strong> Constraints</a></li><li class="chapter-item expanded "><a href="dependent_types/proofs.html"><strong aria-hidden="true">5.2.</strong> Proofs</a></li><li class="chapter-item expanded "><a href="dependent_types/dependent_types.html"><strong aria-hidden="true">5.3.</strong> Dependent Types</a></li></ol></li><li class="chapter-item expanded "><a href="summary/SUMMARY.html"><strong aria-hidden="true">6.</strong> Implementation</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="implementation/low_level.html"><strong aria-hidden="true">6.1.</strong> Low-level Semantics</a></li><li class="chapter-item expanded "><a href="implementation/run_rep.html"><strong aria-hidden="true">6.2.</strong> Runtime Representation</a></li><li class="chapter-item expanded "><a href="implementation/subset.html"><strong aria-hidden="true">6.3.</strong> Core Subset</a></li><li class="chapter-item expanded "><a href="implementation/specialisation.html"><strong aria-hidden="true">6.4.</strong> Specialisation</a></li></ol></li><li class="chapter-item expanded "><a href="summary/SUMMARY.html"><strong aria-hidden="true">7.</strong> Design</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="design/soundness.html"><strong aria-hidden="true">7.1.</strong> Soundness</a></li><li class="chapter-item expanded "><a href="design/wadlers_law.html"><strong aria-hidden="true">7.2.</strong> Syntax Debates</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Extremely Old</li><li class="chapter-item expanded "><a href="old/allocators.html"><strong aria-hidden="true">8.</strong> Type Aware Allocators</a></li><li class="chapter-item expanded "><a href="old/recursive_types.html"><strong aria-hidden="true">9.</strong> Recursive Types</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The WTy2 Language Specification</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/WTy-2/spec/" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="dependent-pattern-matching-without-green-slime"><a class="header" href="#dependent-pattern-matching-without-green-slime">Dependent Pattern Matching, Without Green Slime</a></h1>
<p>Disclaimer: This is basically a blog post. I should start hosting my own website so I can write real blog posts...</p>
<p>TODO: Add footnotes/references</p>
<p>A classic pain point in proof assistants based on ITT is problems with &quot;green slime&quot;.</p>
<pre><code class="language-agda">foo : (x y : ℕ) → Fin (x + y) → ⊤
foo x y fz = {!!}
foo x y (fs _) = {!!}

</code></pre>
<pre><code>I'm not sure if there should be a case for the constructor fz,
because I get stuck when trying to solve the following unification
problems (inferred index ≟ expected index):
  suc n ≟ x + y
when checking that the pattern fz has type Fin (x + y)
</code></pre>
<p>These arise from how unification problems between neutrals and values are undecidable.</p>
<p>Unification between neutrals and variables is easy: all we need to do is perform a substitution, which is what allows</p>
<pre><code class="language-agda">foo : (x : ℕ) → Fin x → ⊤
foo x fz = {!!}
foo x (fs _) = {!!}
</code></pre>
<p>to be elaborated into</p>
<pre><code class="language-agda">foo : (x : ℕ) → Fin x → ⊤
foo x@.(suc _) fz = {!!}
foo x@.(suc _) (fs \_) = {!!}
</code></pre>
<p>We could attempt a similar translation for more complicated indices, using a <code>with</code>-abstraction</p>
<pre><code class="language-agda">foo : (x y : ℕ) → Fin (x + y) → ⊤
foo x y n with x + y
foo x y fz | x+y = {!!}
foo x y (fs n) | x+y = {!!}
</code></pre>
<p>which, behind-the-scenes, can be elaborated into</p>
<pre><code class="language-agda">foo : (x y : ℕ) → Fin (x + y) → ⊤
foo x y n with x + y
foo x y fz | x+y@.(suc _) = {!!}
foo x y (fs n) | x+y@.(suc _) = {!!}
</code></pre>
<p>This typechecks, but we have lost all connection between the index of the <code>Fin</code> and <code>x + y</code>. Such a <code>with</code> abstraction only works by replacing all occurences of <code>x + y</code> in the context with a new variable, so this is an inherent limitation.</p>
<p>Luckily, using Agda's <code>with ... in ...</code> syntax (or the <code>inspect</code> idiom) we can retain propositional evidence of this connection</p>
<pre><code class="language-agda">foo : (x y : ℕ) → Fin (x + y) → ⊤
foo x y n with x + y in p
foo x y fz | .(suc _) = {!!} -- Here, p : x + y ≡ suc n
foo x y (fs n) | .(suc _) = {!!}
</code></pre>
<p>But this is still inconvenient in two ways:</p>
<ol>
<li>Propositional equality forces the user to manually coerce when necessary. It would be nice to have all <code>x + y</code>s which arise later rewrite to <code>suc n</code> automatically.</li>
<li>We were forced to manually write out the index to abstract over it. If we wanted to pattern match on multiple Fins, would would have to abstract over the index of each. We are doing a program translation by hand.</li>
</ol>
<p>There is also a third, more subtle issue:</p>
<ol start="3">
<li>Sometimes, with abstractions in Agda become &quot;ill-typed&quot;. In the case of <code>foo</code>, this can happen if some expression in the context relies on the <code>Fin</code> being indexed by <code>x + y</code> definitionally to typecheck.</li>
</ol>
<pre><code class="language-agda">Pred : ∀ x y → Fin (x + y) → Set

foo : (x y : ℕ) (n : Fin (x + y)) → Pred x y n → ⊤
foo x y n p with x + y
foo x y fz p | .(suc _) = {!!}
foo x y (fs n) p | .(suc _) = {!!}
</code></pre>
<pre><code>w != x + y of type ℕ
when checking that the type
(x y w : ℕ) (n : Fin w) (p : Pred x y n) → ⊤ of the generated with
function is well-formed
(https://agda.readthedocs.io/en/v2.6.4.2/language/with-abstraction.html#ill-typed-with-abstractions)
</code></pre>
<p>To resolve these last two points, I propose a new syntax: &quot;transport-patterns&quot;. Simply put: we allow a built-in transport operator to appear in patterns, allowing us to match without fear of &quot;green slime&quot; while also binding propositional equality of the indices.</p>
<pre><code class="language-agda">foo : (x y : ℕ) → Fin (x + y) → ⊤
foo x y (coe p fz) = {!!}
foo x y (coe p (fs n)) = {!!}
</code></pre>
<p>In contrast to with-abstractions, we don't try to replace the index expression in the context. Instead, we just replace the variable we matched on with a transported value.</p>
<p>Personally, I think this feature alone is already a huge improvement on the status quo. Of course the user could always resort to doing their own fording transformations, but this often infects many other parts of the development with unnecessary clutter (passing and matching on <code>refl</code>s), i.e. in the cases where unification would have worked out.</p>
<p>More than this, I think my frustration with the manual translations is that they force the user to put thought into what ought to be irrelevant, low-level, implementation details, distracting from the larger developments. i.e. in my opinion, time spent pondering question such as:</p>
<ul>
<li>&quot;Can I abstract over the index here or will that be ill-typed?&quot;</li>
<li>&quot;When a function matches on a datatype indexed by a neutral AND the constructor is <em>also</em> indexed by a neutral, should I do a fording translation of the function or the constructor?&quot;</li>
<li>and &quot;What about if in some cases, one of the neutrals ends up being allowed to reduce to a value just in time for the matches to work out?&quot;</li>
</ul>
<p>is a complete waste of effort.</p>
<p>Fixing the first bullet is harder - we must increase the power of definitional equality. Note it might sound less important (it certainly did to me), but in larger examples, having rewrites apply only once, immediately, can end up giving rise to so-called <code>with</code>-jenga where the order of <code>with</code> abstractions needs to be chosen extremely carefully to have the types work out (i.e. without resorting to copious amounts of manual coercing). Again, in my opinion, time spent finding solutions to puzzles like these is time wasted (even if solving puzzles can sometimes be fun).</p>
<p>Before I proceed to the proposal, I must give credit where it is due. I originally heard this idea from Ollef on the r/ProgrammingLanguages Discord, and worked through a lot of the tricky details with Iurii - thanks for the interesting discussions!</p>
<p>Without further ado, the core idea is thus: Make it possible for the context to contain local rewrite rules (from neutrals to values), subject to an occurs check to prevent loops. We can then define dependent pattern matching as a process which adds such rewrite rules to the context (i.e. as opposed to the usual one-time-substitutions-of-variables-for-patterns).</p>
<p>An important note: the solution here is not &quot;complete&quot;. I believe this is by necessity (a perfect solution would give arbitrary equality reflection and naturally make typechecking undecidable). It is simply designed to handle a majority of easy cases, with the fall-back of transport-patterns (or manual fording) always in reach.</p>
<p>TODO: Add paragraph on the occurs check and why it is necessary</p>
<p>Of course, the scrutinee of a pattern match will not always be a neutral. More severely, what might have started as a mapping from a neutral might become not so if some other pattern match causes the neutral to unblock. Our proposed scheme for handling such cases is as follows:</p>
<ul>
<li>First check if the RHS is a value.</li>
<li>RHS is a neutral: Invert the direction of the rewrite rule and continue (TODO: justify why this shouldn't lead to loops)</li>
<li>RHS is a value: Attempt to unify LHS and RHS
<ul>
<li>LHS and RHS unify: Safely discard the rewrite rule. It is redundant.</li>
<li>LHS and RHS anti-unify: Report the most recent match as impossible and refuse to typecheck the branch.</li>
<li>Typechecker cannot make a decision (e.g: LHS and RHS are functions): (*)</li>
</ul>
</li>
</ul>
<p>The final case, (*), is tricky situation. In the case that this was a new rewrite rule we just attempted to add, we are almost definitely screwed; however, if we have reached this case by reducing the LHS of a previously valid rewrite, then we might hope that applying the rewrite eagerly to everything in the context will mean we are allowed to now discard the rewrite rule and everything will continue to typecheck (even if previously definitionally equal things might now not be definitionally equal - which is odd, but not the end of the world).</p>
<p>However, recall the subtlety highlighted above as problem (3.). Conveniently, the neutral -&gt; value mappings often can help us in these sorts of cases; one perspective on how is that <code>Pred x y : Fin (x + y) → Set</code>, so in the <code>fz</code> branch, we will check <code>fz</code> against <code>Fin (x + y)</code>. As long as we apply our <code>x + y -&gt; suc n</code> rewrite to the goal type, this will succeed!</p>
<p>But of course <code>Pred x y</code> is not a variable, and therefore we cannot record the rewritten type in our context (hence why Agda's <code>with</code>-abstraction immediate one-off rewrites don't work here). Therefore, if we later match on <code>x</code> and <code>y</code> revealing them to both be <code>zero</code>, we will have a problem on our hands. Discarding the rewrite (which now would have the form <code>zero -&gt; suc n</code>) will result in <code>Pred x y fz</code> no longer typechecking! Of course, <code>zero</code> and <code>suc _</code> anti-unify, so we can report an impossible much, but if the problem was more subtle (perhaps we used Church numerals instead of <code>ℕ</code>s) then we would be truly screwed.</p>
<p>So, how do we resolve these cases? I think this has to be some sort of type error, but exactly where to error and what to blame is somewhat debatable. I can think of three different reasonable-ish perspectives:</p>
<ul>
<li>The culprit was that the rewrite rule related values whos type can yield undecidable unification problems. Therefore error much earlier, at the original match.</li>
<li>The culprit is that an expression in the context relied on the rewrite rule but the match made it invalid. Therefore blame the <code>Pred x y n</code> and the match on <code>x</code> and <code>y</code>.</li>
<li>The culprit was that the match on <code>x</code> and <code>y</code> unblocked the LHS of the rewrite rule which forced it to be discarded (i.e. the problem is unrelated to whether such a rewrite rule was necessary validity for the context). Therefore blame the <code>x + y -&gt; suc n</code> rewrite rule and the match on <code>x</code> and <code>y</code>.</li>
</ul>
<p>I'll admit that I am partial to the latter here: I think erroring for any type that could possibly yield an undecidable unification puzzle is too conservative, given this must include any inductive datatype which might contain a function (and of course functions themselves), and also general QITs/HITs (which are pretty exotic constructions, but are also very exciting features which I would like a modern proof assistant to support), and I don't like the idea that adding stuff to your context could cause an error (typechecking being stable under weakening seems desirable).</p>
<p>Now to actually try and implement such a feature! (just kidding, I'm a type theorist, I would never write code)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>WTy2 is a pure, strict, functional programming language based on extrinsic dependent types.</p>
<p>It is being designed with a few goals in mind:</p>
<ul>
<li>Aim for there to be exactly one &quot;best&quot; way to design every abstraction. If there has to be multiple, the relative trade-offs for each should be obvious and small in number.</li>
<li>Allow extremely strong compile-time guarantees (via dependent types), but optionally. It should be possible to start with a program that relies heavily on run-time assertions and bit-by-bit introduce more and more static checks without major refactoring.</li>
<li>To support this, breaking from common philosophy on dependent types, WTy2 does NOT encourage creating many separate datatypes to maintain invariants (correct-by-construction). For example, the idiomatic WTy2 encoding a vector (length-indexed list) is to pass a list and a constraint holding a runtime irrelevant proof that it's length is equal to <code>n</code>, NOT to define a new inductive datatype. The style of invariant-capturing WTy2 encourages is therefore more similar to languages with refinement-type systems. To make this feasible in a dependently typed setting, WTy2 supports subtyping, takes the notion of a kind of singly inhabited types (&quot;<code>Constraint</code>&quot;s) from Haskell and combines this with the concept of &quot;implicit proofs&quot;, enabling powerful inference.</li>
<li>WTy2 is also designed to be (eventually) <strong>blazing fast</strong>. Implementing the type system as-is will be more than enough work for the forseable future, but to avoid shooting itself in the foot if/when focus shifts to performance, some effort is being put into mechanisms for providing the programmer opt-in guarantees about data representation, memory layout, specialisation, compile-time code execution etc... (predominantly via &quot;modes&quot;).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary"><a class="header" href="#summary">Summary</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="core-types"><a class="header" href="#core-types">Core Types</a></h1>
<h2 id="any"><a class="header" href="#any">Any</a></h2>
<p><code>Any</code> is the supertype of all types.</p>
<h2 id="type-type"><a class="header" href="#type-type">Type (<code>Type</code>)</a></h2>
<p><code>Type</code> is the supertype of all &quot;types&quot;. This includes anything which can appear on the RHS of a <code>:</code> binding.</p>
<p>An automatic instance of <code>Type</code> is derived for every type declaration.</p>
<h2 id="constraint-constraint"><a class="header" href="#constraint-constraint">Constraint (<code>Constraint</code>)</a></h2>
<p><code>Constraint</code> represents &quot;constraints&quot;. These can look syntactically similar to bindings (the constraint-versions of binding operators contain an extra <code>:</code> to disambiguate), but instead of bringing variables into scope, they constrain existing values.</p>
<p>Constraints can be created with the built-in <code>~</code>, <code>::</code> and <code>&lt;|</code> operators.</p>
<h2 id="functions-fun"><a class="header" href="#functions-fun">Functions (<code>Fun</code>)</a></h2>
<p>In WTy2, functions are defined as variables which implement the (<code>Open</code>) <code>Fun</code> type, which includes methods <code>arg</code> and <code>res</code> (which return the argument and return types of the function respectively).</p>
<p>Normally, functions in WTy2 are uncurried. The exception is operators, which are always of the form <code>a -&gt; b -&gt; c</code>.</p>
<p>See <a href="basic_concepts/./arrows.html">Core Type Operators</a> for the definition of the <code>(-&gt;)</code> type operator in terms of the built-in <code>Fun</code> type.</p>
<h2 id="tuplesrecordsdependent-pairslists-and-telescopes"><a class="header" href="#tuplesrecordsdependent-pairslists-and-telescopes">Tuples/Records/Dependent Pairs/Lists and Telescopes</a></h2>
<p>In WTy2, the built-in tuples, records, dependent pairs, lists etc... all desugar down to the same datatype - a dependent inductively-defined tuple:</p>
<pre><code class="language-WTy2">datatype DepTup(tele: Tele) where
  (:.) : [ty, rest] (head: ty) -&gt; (tail: rest(head))
       -&gt; DepTup(ty .- rest)
  Nil  : DepTup(NilTele);
</code></pre>
<p>Where <code>Tele</code> is another built-in datatype, a telescope:</p>
<pre><code class="language-WTy2">datatype Tele
  = (.-)    : (ty: Type) -&gt; (rest: t -&gt; Type) -&gt; Tele
  | NilTele : Tele;
</code></pre>
<p>Ordinary lists and tuples can be defined from <code>DepTup</code> pretty trivially:</p>
<pre><code class="language-WTy2">type List(ty: Type)
  = [head: ty, tail: List(ty)]
    '(head :. tail)
  | 'Nil;

type Tuple(tys: List(ty))
  = [ty, rest, head: ty, tail: Tuple(rest)]
    '(head :. tail) &lt;&lt;= { tys ~ ty :. rest }
  | 'Nil;
</code></pre>
<p>More convenient list/tuple syntax and records are implemented as syntax-sugar on top of these datatypes (i.e: <code>(0, 1, 2)</code> becomes <code>0 :. 1 :. 2 :. Nil</code>). Following the structure of how <code>DepTup</code> is defined, fields in dependent records can only depend on fields to the left of them.</p>
<h3 id="unit-"><a class="header" href="#unit-">Unit (<code>()</code>)</a></h3>
<p>The unit type is also defined in terms of <code>DepTup</code>, with <code>()</code> parsed as an ordinary identifier:</p>
<pre><code>() = Nil;
type Unit = '();
</code></pre>
<h3 id="design-note-singleton-tuples"><a class="header" href="#design-note-singleton-tuples">Design Note: Singleton Tuples</a></h3>
<p>WTy2 also supports singleton tuples. The parsing ambiguity of expression in parens vs a singleton tuple is resolved as follows:
<code>(E)</code> where <code>E</code> is an expression - parenthesised expression
<code>(E,)</code> where <code>E</code> is an expression - singleton tuple
<code>(i: E)</code> where <code>i</code> is an identifer and <code>E</code> is an expression - named value (<code>t &lt;: (i: t)</code>)
<code>(i: E,)</code> where <code>i</code> is an identifier and <code>E</code> is an expression - named singleton tuple/singleton record</p>
<h3 id="design-note-bindings"><a class="header" href="#design-note-bindings">Design Note: Bindings</a></h3>
<p>In WTy2, the types of records can look syntactically identical to bindings (LHS of assignments). However, bindings are NOT first-class. <code>return (x: Int)</code> returns a <code>Type</code> which is equal to the record type <code>(x: Int)</code>. <code>do {x: Int} = 4</code> (perhaps intending the LHS expression to reduce down to <code>x: Int</code>) is nonsense.</p>
<h2 id="void"><a class="header" href="#void">Void</a></h2>
<p><code>Void</code> is the subtype of all types. It contains no inhabitants.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="common-type-operators"><a class="header" href="#common-type-operators">Common Type Operators</a></h1>
<p>WTy2 quite a few common type operators (mostly arrows), they are summarised here.</p>
<h2 id="function--"><a class="header" href="#function--">Function (<code>-&gt;</code>)</a></h2>
<pre><code class="language-WTy2">(-&gt;): (t: Type) -&gt; (t -&gt; Type) -&gt; Type
a -&gt; b = (f: Fun) &lt;&lt;= { a &lt;: arg(f) /\ res(f) &lt;: b }
</code></pre>
<p>Dependent function arrow.</p>
<p>In the source language, braces are implicitly added around RHS if necessary.</p>
<h2 id="such-that-"><a class="header" href="#such-that-">Such That (<code>&lt;&lt;=</code>)</a></h2>
<pre><code class="language-WTy2">(&lt;&lt;=): (t: Type) -&gt; (t -&gt; Constraint) -&gt; Type
</code></pre>
<p>Narrows a type, requiring the constraint to be satisfiable for all member values. When pattern matching on values of the type, the constraint is brought into scope.</p>
<h2 id="constructor-"><a class="header" href="#constructor-">Constructor (<code>~&gt;</code>)</a></h2>
<pre><code class="language-WTy2">(~&gt;): (t: Type) -&gt; (t -&gt; Type) -&gt; Type
a ~&gt; b = (a -&gt; b) &amp; Con
</code></pre>
<p>Similar to function arrow, but must be &quot;matchable&quot;. i.e:</p>
<pre><code class="language-WTy2">a ~&gt; b = (f: a -&gt; b) &lt;&lt;= {
    for(x: a, y: a, g: a ~&gt; b) { f(x) ~ g(x) =&gt; f ~ g /\ x ~ y }
  }
</code></pre>
<p>In the source language, braces are implicitly added around RHS if necessary.</p>
<h3 id="design-question-is-generativity-necessary"><a class="header" href="#design-question-is-generativity-necessary">Design Question: Is Generativity Necessary?</a></h3>
<p>Haskell assumes type constructors are both injective, and generative, and the work on unsaturated type families still separates functions into those that are both injective and generative, and those that are not necessarily either. However, the benefit of injectivity (for unification) is generally much more useful than generativity, and furthermore, it could be argued that injectivity meshes better with a notion of constructing/matchability anyway (given pattern synonyms are clearly not generative!). Of course, an arbitrary function paired with a proof of injectivity does not provide a strategy to invert it (which is what is <em>really</em> required for pattern matching) but perhaps that just justifies for two types: injective functions, and matchable constructors (the inference and checking of the latter being built-in to the compiler).</p>
<h2 id="subtype-"><a class="header" href="#subtype-">Subtype (<code>&lt;:</code>)</a></h2>
<pre><code class="language-WTy2">(&lt;:): Type -&gt; Type -&gt; Constraint
t &lt;: u = for(x: t) { x :: u }
</code></pre>
<p>Values of the LHS type can be upcast into ones of the RHS type.</p>
<h2 id="implies-"><a class="header" href="#implies-">Implies (<code>=&gt;</code>)</a></h2>
<pre><code class="language-WTy2">(=&gt;): Constraint -&gt; Constraint -&gt; Constraint
</code></pre>
<p>The RHS constraint can be obtained from the LHS constraint.</p>
<h2 id="forall-for--derivable--"><a class="header" href="#forall-for--derivable--">Forall (<code>for</code>) / Derivable (<code>|-</code>)</a></h2>
<pre><code class="language-WTy2">for : (t: Type, c: t -&gt; Constraint) -&gt; Constraint
(|-): (t: Type, c: t -&gt; Constraint) -&gt; Constraint
</code></pre>
<p>The constraint <code>c(t)</code> is derivable from the typing context <code>t</code> - i.e: quantified constraints. The operator version <code>(|-)</code> exists predominately to allow use of <code>(&lt;&lt;=)</code> on the quantified-over type without requiring additional parenthesis.</p>
<p>In the source language, braces are implicitly added around RHS of (<code>|-</code>) if necessary.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="functions"><a class="header" href="#functions">Functions</a></h1>
<p>WTy2 is a functional programming language, and as such, functions are first-class. Any variable that implements <code>Fun</code> is a function.</p>
<h2 id="lambda-blocks"><a class="header" href="#lambda-blocks">Lambda-Blocks</a></h2>
<p>In WTy2, braces (<code>{}</code>) are used to denote a lambda. Inside the braces, there can be:</p>
<ul>
<li>Just an expression. In this case the argument type is inferred, and can be referred to in the expression as <code>it</code>. The really powerful part here is that variables <code>varName</code> are attempted to be resolved as fields of <code>it</code> first (as in <code>it.varName</code>). This is similar to <code>this</code> being in scope allowing access to fields and methods of the class without needing to specify the receiver in OOP languages.</li>
<li>A &quot;<code>\</code>&quot; followed by an irrefutable pattern which is bound to by the argument, a &quot;<code>|-&gt;</code>&quot;, and the return expression.</li>
<li>Multiple <code>|</code>s, each followed by a pattern, a <code>|-&gt;</code> and a return expression for if that match succeeds.</li>
</ul>
<h2 id="function-definitions"><a class="header" href="#function-definitions">Function Definitions</a></h2>
<p>WTy2 is a functional programming language, meaning functions are first class and can be bound to variables. Using only existing introduced syntax, a function that adds three integers can be defined like so:</p>
<pre><code class="language-wty2">addTriple: Tuple(Int, Int, Int) -&gt; Int = { \(x, y, z) |-&gt; x + y + z };
</code></pre>
<p>Using record syntax (and implicit <code>it</code> scoping), we can achieve this in a slightly cleaner way as</p>
<pre><code class="language-wty2">addTriple: (x: Int, y: Int, z: Int) -&gt; Int = { x + y + z };
</code></pre>
<p>WTy2 introduces an additional way to define functions, which looks closer to imperative programming languages:</p>
<pre><code class="language-wty2">addTriple(x: Int, y: Int, z: Int): Int = x + y + z;
</code></pre>
<p>In general <code>f(t): u</code> can be thought of as equivalent to...</p>
<ul>
<li>If <code>t</code> is a type (including record types), <code>f: t -&gt; u</code></li>
<li>If <code>t</code> is a list of types, <code>f: Tuple(t) -&gt; u</code> <sup class="footnote-reference"><a href="#note">1</a></sup></li>
</ul>
<p>With one extra special case: if the syntax is used as the LHS of an assignment (like above) then the braces around the RHS expression are implicit.</p>
<h2 id="recursion"><a class="header" href="#recursion">Recursion</a></h2>
<p>TODO</p>
<p><sup class="footnote-reference"><a href="#note">1</a></sup> This rule is specifically intended to make signatures of higher-order functions easier to write.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="records"><a class="header" href="#records">Records</a></h1>
<p>Records in WTy2 are internally compiled down to ordinary dependent tuples, but have a few extra features.</p>
<h2 id="construction"><a class="header" href="#construction">Construction</a></h2>
<p>Records in WTy2 can be constructed similarly tuples but with each expression prefixed the field name and an <code>=</code> symbol: <code>(field1=expr1, field2=expr2, ..., fieldN=exprN)</code> to create a record of type <code>(field1: type1, field2: type2, ..., type3)</code>.</p>
<h2 id="subtyping"><a class="header" href="#subtyping">Subtyping</a></h2>
<p>Records are covariant in types of fields.</p>
<p>There is also one subtyping rule between records and tuples to allow for passing functions that take named arguments to higher order functions cleanly (recall functions are contravariant in argument type).</p>
<pre><code class="language-WTy2">(Ty1, Ty2, ..., TyN) &lt;: (field1: Ty1, field2: Ty2, ..., fieldN, TyN);
</code></pre>
<h2 id="shuffling"><a class="header" href="#shuffling">Shuffling</a></h2>
<p>WTy2 defines a primitive <code>shuffle</code> to work with records with different orders of field names:</p>
<pre><code class="language-WTy2">shuffle: [a](x: a, b: Type) &lt;&lt;= { a: permutation(b) } -&gt; b;
</code></pre>
<p>Where <code>permutation</code> is a type family that produces a type containing all record types that are permuations of the fields of the argument record.</p>
<h2 id="partial-application-"><a class="header" href="#partial-application-">Partial Application (&quot;<code>?</code>&quot;)</a></h2>
<p>WTy2 supports a <em>nominal</em> <sup class="footnote-reference"><a href="#note">1</a></sup> partial application syntax based on records, which leverages yet another primitive:</p>
<pre><code class="language-WTy2">partialise: (f: a -&gt; b) -&gt; [a1] a0 &lt;&lt;= { concat(a0, a1): permutation(b) }
           -&gt; if(isUnit(a1)) { b }.else { a1 -&gt; b };
</code></pre>
<p>Where <code>concat</code> is a type family which concatenates two records in the obvious way and <code>isUnit</code> is a function on (record) types which decides if the type is <code>()</code> (one implementation would be <code>isUnit(a: Rec) = a.size() == 0</code>).</p>
<p>One way to view this primitive is as a generalised <code>curry</code> which infers desired argument order based on record field names.</p>
<p>As syntax sugar, WTy2 allows <code>(?) = partialise</code> to be used a primitive operator which binds tighter than function application, allowing use like:</p>
<pre><code class="language-WTy2">f: (x: Int, y: Char, z: Bool) -&gt; Int;

g: (y: Char) -&gt; Int = ?f(x=3, z=True);
</code></pre>
<p>In the case <code>a0: permutation(b)</code>, we have <code>a1 :: () =&gt; isUnit(a1) ~ True</code>. We special-case this situation in the type signature to allow for convenient passing of records with shuffled field order to functions:</p>
<pre><code class="language-WTy2">w: Int = ?f(y='a', z=False, x=3);
</code></pre>
<p>It is likely inference for this primitive will need to be handled specifically in the typechecker (i.e: to take advantage how <code>a1</code> can be inferred by removing fields of <code>b</code> that occur in <code>a0</code>).</p>
<p><sup class="footnote-reference"><a href="#note">1</a></sup> As opposed to <em>positional</em>, which is the usual approach in languages supporting partial application, such as Haskell. For example, given the Haskell function <code>foo a b = a / b</code> we can easily partially apply <code>foo</code> to a numerator, <code>n</code>, with <code>foo n</code>, but partially applying to a denominator, <code>d</code>, requires more clunky syntax such as <code>(`foo` a)</code> or a combinator like <code>flip</code> or <code>(&amp;)</code>. This problem gets worse as the arity of functions increases.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="declarations"><a class="header" href="#declarations">Declarations</a></h1>
<p>WTy2 supports top-level bindings in the form of &quot;declarations&quot;.</p>
<p>All named declarations can be prefixed with visibility annotations.</p>
<h2 id="type-declarations"><a class="header" href="#type-declarations">Type Declarations</a></h2>
<p>Type declarations create new types or type constructors. Types formed with constructors declared via type declarations are irreducible terms of type <code>Type</code>.</p>
<p>Unlike many other formal type systems, user-defined types in WTy2 can be &quot;open&quot;, meaning we can, in a distinct module, declare more sets of terms as members of the original type.</p>
<p>Open types can have a number of associated members (specifically, functions) that must be defined for all implementors of that type. The type signatures of these functions can refer to the implementor of the type: <code>self</code>. Indeed, each of these functions must take at least one explicit (i.e: runtime relevant) argument (the &quot;receiver&quot;) of type <code>self</code>, <code>impl(self)</code> or <code>'self</code> (a practical limitation to make type inference and compiling to VTables possible).</p>
<p>Super-constraints that all implementors must obey can also be declared using <code>&lt;&lt;=</code> followed by an function of type <code>(self: DeclaredType) -&gt; Constraint</code>. This introduces <code>for(self: DeclaredType) { f(self) }</code> (where <code>f</code> is the super-constraint function) into the context, which is applied eagerly during typechecking, so care must be taken by the user to avoid writing super-constraints that loop. Requiring laws without the eager-expansion behaviour can be done through requiring function members of appropriate type (e.g: <code>fmap_id(f: self): Proof(fmap?(f: id) ~ id)</code>)</p>
<p>As an example, here is the <code>ParMonad</code> type, which is similar to a <code>Monad</code> in functional languages like <code>Haskell</code> but does not require the type constructor to be total (meaning it can support data structures like sets and hashmaps).</p>
<pre><code class="language-WTy2">type ParMonad where {

    fmap[a: arg(self), b: arg(self)](x: self(a), f: a -&gt; b): self(b)

    pure[a: arg(self)](m: 'self, x: a): self(a)

    (&gt;&gt;=)[a: arg(self), b: arg(self)](x: self(a), f: a -&gt; self(b)): self(b)

} &lt;&lt;= { [domain: Type] self :: domain ~&gt; Type };
</code></pre>
<p><sup class="footnote-reference"><a href="#note">1</a></sup></p>
<h3 id="type-synonyms"><a class="header" href="#type-synonyms">Type Synonyms</a></h3>
<p>Sometimes a type is desired that is simply a synonym for some other more elaborate type. As types are first class, this can be implemented in WTy2 just with ordinary terms; however, term definitions have slightly different semantics to created types (terms reduce, while types do not) which can impact typechecking and inference.</p>
<p>Type synonyms can be alternatively written by declaring a type with the appropriate super-constraint and then writing instances to cover every value (if the type being aliased is open type, the instance head can be <code>impl(OpenType)</code>).</p>
<pre><code class="language-WTy2">datatype Foo
  | MkFoo
  ;

type Alias {} &lt;&lt;= { self &lt;| Foo };

inst Alias for MkFoo;
</code></pre>
<p>This pattern is quite clunky (especially for closed types with many constructors), so WTy2 provides syntax sugar for it:</p>
<pre><code>type Alias = Foo;
</code></pre>
<p>As coherence rules enforce that instances where the instance head is an open type prevent any other instances being written, it is suggested that ideal practice when writing an open-head instance is to instead write a type alias. Implementations may wish to warn the programmer in when this is not done.</p>
<h2 id="instance-declarations"><a class="header" href="#instance-declarations">Instance Declarations</a></h2>
<p>Instance declarations in WTy2 are denoted with the <code>inst</code> keyword followed by the open, inst-able type and the instance head (separated with <code>for</code>). Every instance adds <code>Head :: InstableType</code> to the context.</p>
<p>The instance head type must not have any stuck terms and must not overlap with other instance types (the conditions of overlap are given fully in <a href="basic_concepts/./coherence.html">Coherence</a>).</p>
<h2 id="data-declarations"><a class="header" href="#data-declarations">Data Declarations</a></h2>
<p>Data declarations define &quot;variants&quot; or &quot;tags&quot;. These are similar to functions but instead of producing arbitrary values after executing some computation, they create tagged versions of whatever type they are declared to take as parameter.</p>
<p>The suggested implementation is for tags to all share the same 32-bit space of values. As an optimisation, it is suggested that this tag is elided in cases where it is known at compile-time.</p>
<p>I.e: In the below program</p>
<pre><code class="language-WTy2">data Foo(Bar)

x: Bar = ...
y: Foo = Foo(x)
</code></pre>
<p>Both <code>Foo</code> and <code>Bar</code> should have equivalent runtime representations.</p>
<p>Handling variance while ensuring unnecessary tag information is not stored at runtime is not a trivial problem: for how this is solved specifically with regards to recursive types, see the dedicated section.</p>
<h2 id="datatype-declarations"><a class="header" href="#datatype-declarations">Datatype Declarations</a></h2>
<p>Unfortunately, some types might need many variants that would quickly fill up a 32-bit space of values (for example: int32s). A datatype declaration looks a bit closer to an inductive type declaration in other functional languages, and is implemented by having an outer tag which takes one slot of the 32-bit space, then allowing the variants all make use of a separate space of values.</p>
<p>Datatype declarations are also just convenient in allowing the user to simultaneously define a type and set of variants.</p>
<pre><code class="language-WTy2">datatype Bool
  | True
  | False
  ;
</code></pre>
<h2 id="functionconstant-declarations"><a class="header" href="#functionconstant-declarations">Function/Constant Declarations</a></h2>
<p>Ordinary terms like functions or constants can also be defined as top level bindings. They do not need to be prefixed with any keyword.</p>
<h3 id="proof-declarations"><a class="header" href="#proof-declarations">Proof Declarations</a></h3>
<p>However, functions can be optionally be prefixed with the <code>proof</code> keyword. This changes the semantics of the binding, allowing calls to the function to be inserted automatically to aid typechecking. <code>proof</code>s my also be anonymous. See the <a href="basic_concepts/../dependent_types/proofs.html">dedicated section</a> on <code>proof</code>s for more information.</p>
<div class="footnote-definition" id="note"><sup class="footnote-definition-label">1</sup>
<p>The the <code>a: arg(self)</code> and <code>b: arg(self)</code> constraints here are slightly tiresome. Arguably these could be inferred from their use as arguments to <code>self</code>. There has been some research in Haskell on doing this inference https://richarde.dev/papers/2020/partialdata/partialdata.pdf and it appears to be highly effective in practice. The downside of doing this in the general case (adding constraints implicitly to a type signature until the signature typechecks) is that more changes can become breaking (see <a href="https://github.com/rust-lang/rfcs/blob/master/text/2089-implied-bounds.md">Rust FFC 2089</a>)</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="erasure-and-visibility"><a class="header" href="#erasure-and-visibility">Erasure and Visibility</a></h1>
<h1 id="runtime-relevance-of-types-and-constraints"><a class="header" href="#runtime-relevance-of-types-and-constraints">Runtime Relevance of Types and Constraints</a></h1>
<p>In Haskell, runtime relevance can effectively be summarised as: types are erased, constraints are not. Even equality constraints like <code>a ~ b</code> which don't contain any fields often do not get fully optimised away as <code>Constraint</code> is lifted and so could point to a bottoming value (see discussion at https://github.com/ghc-proposals/ghc-proposals/pull/547).</p>
<p>In WTy2, we take the opposite approach: constraints are erased but types are not. To perform dispatch, implementations will in all likelyhood need to implement some sort of runtime.</p>
<h1 id="erasure-and-visibility-in-types-and-values"><a class="header" href="#erasure-and-visibility-in-types-and-values">Erasure and Visibility in Types and Values</a></h1>
<p>Even though values and types must in general be kept around at runtime, in many specific cases, this is not necessary (consider a generic function which takes both a type <code>t :|=&gt; Animal</code> and an argument <code>a: t</code> - <code>t</code> can be recovered entirely from <code>a</code>). The key observation made here is that arguments we would like the typechecker infer for convenience generally correspond with ones recover.</p>
<p>A type surrounded in parenthesis can be prefixed with something that looks similar to a record type but the bindings are placed inside brackets (<code>[]</code>) instead of parenthesis.</p>
<p>A variable can be bound in the erased elements of a record only if:</p>
<ul>
<li>It occurs by itself in a matchable function application (i.e: as an argument or the function itself) to the right of a member constraint and the type (i.e: RHS object of member constraint) is <code>Closed</code> (the <code>Closed</code> constraint is inferred if the use of <code>[]</code>s require it, similar to definedness constraints which arise from function applications in types). <sup class="footnote-reference"><a href="#note">1</a></sup></li>
<li>It is on the RHS of an equality constraint with a non-erased element (unclear if this is actually useful).</li>
</ul>
<p>An example of erasure being useful is when working with length-indexed vectors:</p>
<pre><code class="language-WTy2">vecLen[t: Type, n: Nat](v: Vec(t, n)): Nat &lt;&lt;= { it ~ n }

returnsVecOfUnknownLen(...): [n: Nat] Vec[Bool, n]
</code></pre>
<p>In <code>vecLen</code>, binding <code>t</code> and <code>n</code> in the <code>[]</code>s allows them to be inferred, and makes it so there is no runtime cost of having to pass the type or length. Note if we had to pass the length explicitly, then the function would be entirely useless: we would need to know the length to calculate it!</p>
<p>This combines nicely with functions like <code>returnsVecOfUnknownLen</code>. If we ever do actually need to know the length (perhaps to pattern match on it), then we can call <code>vecLen</code> on the result, and this all works out because we still have an erased <code>n: Nat</code> in scope.</p>
<p>To be concrete, a term being erased means that it cannot be pattern matched on, or passed as an argument to somewhere where a non-erased term is expected.</p>
<p>Unlike constraints in <code>&lt;&lt;=</code>, erased terms in records can be manually specified at construction or bound when matching.</p>
<pre><code class="language-WTy2">[erasedLen=n] vec = returnsVecOfUnknownLen(...);
len = vecLen[Bool, erasedLen](vec);

// From the signature of 'vecLen', `erasedLen ~ len` is in the context
_: () &lt;&lt;= { erasedLen ~ len } = ();
</code></pre>
<h2 id="bidirectional-type-inference"><a class="header" href="#bidirectional-type-inference">Bidirectional Type Inference</a></h2>
<p>One unfortunate consequence of handling inference in this way is that setting up constraints based on the desired return type (bidirectional type inference) is not really possible. This can be a useful feature - for example, in languages like Haskell, numeric expressions can stay entirely in terms of <code>Num a =&gt; a</code> until finally being instantiated to a specific numeric type at call-site, but it also leads to many cases of potential ambiguity and arguably makes code harder to reason about.</p>
<p><sup class="footnote-reference"><a href="#note">1</a></sup> Note this is less restrictive than it might initially sound. If we have <code>x: Animal</code> and a function <code>id[t: Type](x: t): t</code>, <code>id(x)</code> does indeed typecheck, with <code>t</code> instantiated to <code>x.head(Animal)</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="coherence"><a class="header" href="#coherence">Coherence</a></h1>
<p>WTy2 has a number of rules on instance declarations to guarantee instances do not overlap. Note &quot;overlap&quot; has a slightly stronger meaning in WTy2 than in other languages with typeclasses given the ubiquity of subtyping: treated as sets, there should exist no value that is a member of both types.</p>
<p>Rules around instances and overlap can get tricky, and luckily, a lot of prior work has been done investigating them in languages such as Rust and Haskell. As such, I will repeatedly refer to the decisions those languages have taken to compare and contrast.</p>
<h2 id="detecting-errors-early"><a class="header" href="#detecting-errors-early">Detecting Errors Early</a></h2>
<p>A goal of WTy2 is that adding a valid instance (i.e: no error is detected at the site of the instance) should never break existing code.</p>
<p>Note that Haskell does not actually meet this criteria due to overlap only being checked lazily (when trying to solve the constraint), see:</p>
<pre><code class="language-hs">class C a

instance C (Char, a)

-- This instance appears to be fine, but causes an error at the
-- call to `bar` due to the instance of `C` becoming ambiguous
{-
instance C (a, Bool)
-}

foo :: ()
foo = bar ('a', True)

bar :: C a =&gt; a -&gt; ()
bar _ = ()
</code></pre>
<p>Following this rule doesn't just lead to a theoretically cleaner language, it has a direct practical benefit: adding new valid instances to a library can never be a breaking change and so does not require a semantic version bump.</p>
<h2 id="outermost-constructors"><a class="header" href="#outermost-constructors">Outermost Constructors</a></h2>
<p>Given WTy2 is dependently typed with types effectively modelling arbitrary sets, checking if an arbitrary two types overlap is obviously undecidable. We can trivially encode Fermat's last theorem as a type overlap problem.</p>
<pre><code class="language-WTy2">type C { };
inst C for (x: Int, y: Int, z: Int) { };
inst C for [n: Int] (x: Int, y: Int, z: Int) &lt;&lt;= { x ^ n + y ^ n ~ z ^ n } { };
</code></pre>
<p>We take the conservative approach of only considering the outermost constructor(s)<sup class="footnote-reference"><a href="#note">1</a></sup>. For example, the two below instances will always be treated as overlapping (regardless of whether <code>Foo</code> and <code>Bar</code> overlap):</p>
<pre><code>data Mk[a: Type](x: a);

type Foo : Type = ...

type Bar : Type = ...

type C { };

inst C for [x: Foo] 'Mk(x) { };
inst C for [x: Bar] 'Mk(x) { };
</code></pre>
<p>The check for overlap between closed types then becomes quite simple. The instance head types are reduced into form <code>[...] 'C0(...) | [...] 'C1(...) | ...</code> and the sets of outermost constructors are compared.</p>
<p>As well as making overlap rules MUCH simpler, this has a really poweful benefit for implementation. (I believe that) with it, we can fully erase constraints (instead keeping tags around at runtime, and dispatching based off the outer tag).</p>
<p>I further argue (though more loosely) that this has a further advantage in program reasoning, similar to parametricity. Consider defining a <code>Num</code> instance for lists. Haskell would allow defining a <code>Num</code> instance for <code>List Int</code> which operates with <code>zipWith</code> and <code>List SomethingElse</code> which concatenates lists with <code>(+)</code>, removes elements from the first list on <code>(-)</code> etc... I personally believe the solution mandated by WTy2 of defining a separate list datatype to correspond with each of the instances behaviours (or at the very least a newtype wrapper) leads to clearer code.</p>
<h2 id="openclosed-rules"><a class="header" href="#openclosed-rules">Open/Closed Rules</a></h2>
<p>Types can either be open or closed. These properties interact with the <code>(|)</code> and <code>(&amp;)</code> type operators like so:</p>
<pre><code class="language-WTy2">for(t: Closed, u: Closed) { t | u :: Closed }
for(t: Open, u: Type)     { t | u :: Open   }
for(t: Closed, u: Type)   { t &amp; u :: Closed }
for(t: Open, u: Open)     { t &amp; u :: Open   }
</code></pre>
<p>Types are closed iff their supertype is closed. Recall that</p>
<pre><code class="language-WTy2">type T = U;
</code></pre>
<p>...is translated into:</p>
<pre><code class="language-WTy2">type T { } &lt;&lt;= { self &lt;| impl(U) };
inst T for impl(U); // Or an instance for every value if `U` is not open.
</code></pre>
<p>So for type-alias syntax, the defined type is closed iff the RHS type is closed.</p>
<p>A type may have exactly one &quot;open&quot; instance, or many &quot;closed&quot; instances.</p>
<p>If the equivalent of a WTy2 &quot;open&quot; type in Rust is considered to be a blanket impl (as opposed to an impl for a concrete type), then the rules Rust uses are actually a bit more flexible. It allows:</p>
<pre><code class="language-rs">struct S1;
struct S2;
struct S3;

trait T1 {}
trait T2 {}
trait T3 {}

impl &lt;T: T2&gt; T1 for T {}

impl T1 for S1 {}

impl T1 for S2 {}

// This impl, if uncommented, will cause an overlap with the blanket impl, but
// only indirectly - the error message will not point to this line!
//impl T2 for S2 {}
</code></pre>
<p>In my opinion, this is a mistake: the error message not highlighting the correct line is confusing to the programmer, the rules which allow this are necessarily more complicated and I would argue this pattern has very limited utility (OOP has proven that default instances for a type in terms of another are useful, but this can be achieved through much more principled means like Haskell's <code>deriving via</code>).</p>
<h2 id="orphan-rules"><a class="header" href="#orphan-rules">Orphan Rules</a></h2>
<p>To avoid overlap even when multiple modules are involved, WTy2 disallows &quot;orphan instances&quot;. The gist is that, either the instance-d type and or every outer constructor of the instance head must be defined in the same module as the instance declaration.</p>
<p>Haskell only reports a warning on orphan instances rather than an outright error. I believe this is a mistake - orphan instances can trivially lead to overlap and overlap can lead to incoherence.</p>
<div class="footnote-definition" id="note"><sup class="footnote-definition-label">1</sup>
<p>This (perhaps not entirely coincidentally) closely mirrors the syntactic restriction on <a href="https://www.haskell.org/onlinereport/haskell2010/haskellch4.html#x10-770004.3.2">Haskell 2010</a> instance heads (i.e: without <code>-XFlexibleInstances</code>).</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="modules"><a class="header" href="#modules">Modules</a></h1>
<p>WTy2 programs are organised into modules, similar to Haskell (so modules are not first-class/intended as a method of abstraction - open <code>type</code>s suit that purpose well already).</p>
<h2 id="importsexports"><a class="header" href="#importsexports">Imports/Exports</a></h2>
<p>The public exports of a module are written in parens after the module declaration. Imports of a module are written in parens after the name of the imported module. Publically exported members are considered part of the public API of a module and breaking changes to them reflect semantic version changes for the module.</p>
<p>If and only if the exact version of the dependended-upon module is specified in the package file is the programmer given the freedom to import members that are not publically exported (still with a warning).</p>
<p>Requirement: Non-semantic version changes of upstream modules should never cause compile errors in downstream modules.</p>
<h2 id="module-members"><a class="header" href="#module-members">Module Members</a></h2>
<p>Module members include top-level variables, types, tags, instances and <code>proof</code>s.</p>
<ul>
<li>Variables, <code>v : t = e</code>, and their types (<code>v : t</code>) can be exported/imported via their identifer. The RHS of their definition (<code>v ~ e</code>) can be exported/imported with <code>(..)</code>.</li>
<li>Closed types, <code>type t = u</code>, can be exported/imported via their identifiers. The RHS (<code>t &lt;: u /\ u &lt;: t</code>) can be exported/imported with <code>(..)</code>.</li>
<li>Open types, <code>type t { m0: t0; m1: t1; }</code>, can be exported/imported via their identifiers. Members of the type can be exported/imported in parens. Instances can only be made if all members are in scope via <code>(..)</code>.</li>
<li>Instances,<code>impl t for u { m0 := e0; m1 := e1; }</code> , are exported/imported implicitly. How to signal intent for whether to export the definition of members of the instance (<code>m0 ~ e0</code>) can be done by writing the special syntax <code>m0(..) for u</code>.</li>
<li>Tags can be exported via their identifers. Modifying the type of arguments to a tag is always a breaking change.</li>
<li><code>proof</code>s <code>proof p := e</code> are exported/imported as functions via their identifiers and imported as unnamed <code>proof</code>s with <code>proof(p)</code> (they are always exported as unnamed <code>proof</code>s). A named <code>proof</code> can be imported as both a function and an unnamed <code>proof</code> by a downstream module. All proofs can be imported as unnamed at once with <code>proof(..)</code>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-1"><a class="header" href="#summary-1">Summary</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="utilities"><a class="header" href="#utilities">Utilities</a></h1>
<p>WTy2's syntax is designed for allowing defining functions that appear similar to built-in language constructsof other languages. Below are a few examples:</p>
<h2 id="do"><a class="header" href="#do">Do</a></h2>
<p>Inspired by Haskell</p>
<pre><code class="language-WTy2">do(f: () -&gt; t): t = f()
</code></pre>
<p>This is primarily useful when defining functions in <code>f(x: t): u = ...</code>-style where you still want to use a block to define locals or use <code>do</code>-notation sugar <sup class="footnote-reference"><a href="#note">1</a></sup>. E.g:</p>
<pre><code class="language-WTy2">foo(x: Int, y: Int): Int = do {
    z := x * 3;
    w := y - 2;
    (z * z + w) / (x + w)
}
</code></pre>
<h2 id="if-elif-else"><a class="header" href="#if-elif-else">If-Elif-Else</a></h2>
<p>Inspired by oh-so-many programming languages, maybe Algol 60 was first?</p>
<pre><code class="language-WTy2">if[t: Type](c: Bool, e: () -&gt; t): Maybe(t) = with(c) {
| True  -&gt; Just(e()),
| False -&gt; Nothing
}
</code></pre>
<pre><code>elif[t: Type](x: Maybe(t), c: Bool, e: () -&gt; t): Maybe(t) = with(x, c) {
| (Just(y), _)     |-&gt; x,
| (Nothing, True)  |-&gt; Just(e()),
| (Nothing, False) |-&gt; Nothing,
}
</code></pre>
<pre><code class="language-WTy2">else[t: Type](x: Maybe(t), e: () -&gt; t): t = with(x) {
| Just(y) |-&gt; y,
| Nothing |-&gt; e()
}
</code></pre>
<p>E.g:</p>
<pre><code class="language-WTy2">_ := if(True) {
  &quot;Case one!&quot;
}.elif(False) {
  &quot;Case two!&quot;
}.else {
  &quot;Case three!&quot;
}
</code></pre>
<h2 id="fun"><a class="header" href="#fun">Fun</a></h2>
<p>Inspired by Kotlin</p>
<pre><code class="language-WTy2">fun[r: Type](t: Type, f: t -&gt; r): t -&gt; r = f
</code></pre>
<p>In WTy2, serves to annotate the argument type of a function without having to use arrow-lambda syntax.</p>
<h2 id="lazy"><a class="header" href="#lazy">Lazy</a></h2>
<p>Inspired by Scala</p>
<pre><code class="language-WTy2">lazy[t: Type](f: () -&gt; t): () -&gt; t = f
</code></pre>
<p>Note this does not perform any memoisation (call-by-need). This would require some form of mutability to implement.</p>
<h2 id="the"><a class="header" href="#the">The</a></h2>
<p>Inspired by Idris</p>
<pre><code>the(t: Type, x: t): t = x
</code></pre>
<p>Annotates the type of <code>x</code>.</p>
<h2 id="with-and-also"><a class="header" href="#with-and-also">With and Also</a></h2>
<p>Inspired by Kotlin</p>
<pre><code class="language-WTy2">with[t: Type, r: Type](x: t, f: t -&gt; r): r = f(x)
</code></pre>
<pre><code class="language-WTy2">also[t: Type, m: Applicative](x: t, f: t -&gt; m()): m(t) = f(x) $&gt; x
</code></pre>
<p><code>with</code> combines well with lambda-case syntax as a way to pattern match on a variable. E.g:</p>
<pre><code class="language-WTy2">_ := with(x) {
| 0 |-&gt; &quot;Zero!&quot;,
| 1 |-&gt; &quot;One!&quot;,
| _ |-&gt; &quot;Other!&quot;
}
</code></pre>
<h2 id="tagged"><a class="header" href="#tagged">Tagged</a></h2>
<pre><code class="language-WTy2">tagged[a: Type](f: a ~&gt; Any): Type = [x: a] 'f(x)
</code></pre>
<p>Returns the set of all values tagged with the constructor.</p>
<h2 id="impl"><a class="header" href="#impl">Impl</a></h2>
<pre><code class="language-WTy2">impl(t: Type): Type = [u: t] u
</code></pre>
<p>The union of all types which implement an open type.</p>
<p><sup class="footnote-reference"><a href="#note">1</a></sup> Of course in WTy2, <code>do</code>-notation is not really related to the <code>do</code> utility defined here; it can be used in any block. &quot;Braces-notation&quot; doesn't quite roll of the tongue though...</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-2"><a class="header" href="#summary-2">Summary</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="constraints"><a class="header" href="#constraints">Constraints</a></h1>
<p>Constraints (<code>Constraint</code>) in WTy2 are used to pass evidence of equality or type membership, inspired by Haskell's <code>Constraint</code> kind.
Unlike Haskell, WTy2 retaining tags at runtime means that dictionary-passing is not the only sensible implementation strategy (we can instead just dispatch on tags) but viewing <code>Constraint</code> as the set of types which are guaranteed to only have one value (i.e, if we were allowed to name members of constraints in WTy2, we would have <code>for(c: Constraint, x: c, y: c) { x ~ y }</code>), with appropriate inference rules, is still sensible.</p>
<h2 id="constraint-operators"><a class="header" href="#constraint-operators">Constraint Operators:</a></h2>
<ul>
<li><code>x :: t</code> = Dual to the binding operator <code>:</code>. Variable <code>x</code> is a member of the type <code>t</code>.</li>
<li><code>t &lt;| u</code> = Dual to the binding operator <code>&lt;:</code>. Type <code>t</code> is a subtype of <code>u</code>.
This is actually not built-in. We can define it as <code>t &lt;| u := for(x: t) { x :: u }</code></li>
<li><code>x ~ y</code> = Variable <code>x</code> is equal to <code>y</code>. Specifically, reduces to the same normal form, or if a function, is extensionally equal.</li>
<li><code>c /\ d</code> = A <strong>constraint conjunction</strong>. Both constraint <code>c</code> and constraint <code>d</code> are derivable.</li>
<li><code>c =&gt; d</code> = A <strong>constraint implication</strong>. Constraint <code>d</code> is derivable if constraint <code>c</code> is assumed.</li>
<li><code>for(t, f)</code> = A <strong>quantified constraint</strong>. Function taking argument of type <code>t</code> and returning a constraint, <code>f</code> returns a derivable constraint for every value of type <code>t</code>.
Example usage: <code>for(x: Int, y: Int) { x + y ~ y + x }</code> represents the constraint that <code>(+)</code> on <code>Int</code>s is commutative.</li>
<li>Constraints, like types, are first-class. The type of constraints is <code>Constraint</code> and so arbitrary expressions of this type can also appear inside constraints.</li>
</ul>
<h2 id="such-that--1"><a class="header" href="#such-that--1">Such That <code>(&lt;&lt;=)</code></a></h2>
<p>WTy2 features a built-in dependent operator that places additional constraints on values of a type. When used on the argument and return type of a function, this has the interpretation of defining <strong>requires</strong> and <strong>ensures</strong> contracts, respectively.</p>
<p>The <code>&lt;&lt;=</code> operator has the following type signature:</p>
<pre><code class="language-WTy2">(&lt;&lt;=) : (a: Type, f: a -&gt; Constraint) -&gt; Type
</code></pre>
<p>To construct a value of type <code>a &lt;&lt;= b</code> from a value <code>x</code> of type <code>a</code>, <code>b(x)</code> must be in the context. Matching on a value of type <code>(x: a) &lt;&lt;= b</code> is equivalent in syntax to matching on a value of type <code>a</code>, but <code>b(x)</code> is implicitly added to the typing context.</p>
<p>Another interpretation of this operator that might be more intuitive for programmers who have used languages with dependent types before is as a dependent pair, where the second element must be a constraint dictionary.</p>
<p>An approximation of this operator in Idris2 could be defined like so (using boolean predicates lifted to the type level instead of Haskell-style constraints, which Idris2 does not really have https://www.idris-lang.org/docs/idris2/current/base_docs/docs/Data.So.html):</p>
<pre><code class="language-idris">data (&lt;&lt;=) : (a: Type) -&gt; (p: a -&gt; Bool) -&gt; Type where
  Mk : forall a, p. (x: a) -&gt; { auto f: So (p x) } -&gt; ((&lt;&lt;=) a p)

infix 4 &lt;&lt;=
</code></pre>
<p>An example use would be to restrict the integers received by a function: <sup class="footnote-reference"><a href="#note">1</a></sup></p>
<pre><code class="language-idris">total
foo : (Nat &lt;&lt;= \x =&gt; 1 &lt;= x &amp;&amp; x &lt;= 3) -&gt; ()
foo (Mk 1) = ()
foo (Mk 2) = ()
foo (Mk 3) = ()
</code></pre>
<p>We can see that although <code>foo</code> only matches on the natural number being <code>1</code>, <code>2</code> or <code>3</code>, the function is still correctly checked as <code>total</code>, as we must also pass a proof that the <code>Nat</code> is in the range <code>[1-3]</code>.</p>
<p>The equivalent WTy2 declaration of <code>foo</code> is:</p>
<pre><code class="language-WTy2">foo(x: Nat) &lt;&lt;= { (1 &lt;= x &amp;&amp; x &lt;= 3) ~ True }
</code></pre>
<p>Note in this signature, <code>foo</code> is declared as a function which takes an argument of type <code>(x: Nat) &lt;&lt;= { (1 &lt;= x &amp;&amp; x &lt;= 3) ~ True }</code>. This idea extends, we could define a type synonym and use that instead:</p>
<pre><code class="language-WTy2">type NatBetween(min: Nat, max: Nat)
    = Nat &lt;&lt;= { min &lt;= it &amp;&amp; it &lt;= max ~ True }

foo(x: NatBetween(1, 3))
</code></pre>
<h3 id="design-note-equivalent-constraints"><a class="header" href="#design-note-equivalent-constraints">Design Note: Equivalent Constraints</a></h3>
<p>You may notice that given constraints can contain arbitrary expressions, we could formulate semantically-equivalent constraints in many different ways. For example, we could write <code>{ contains([1, 2, 3], it) ~ True }</code>, or even <code>{ max(1, min(3, it)) ~ it }</code>. That these constraints do indeed imply each other is not always obvious (especially to the typechecker).</p>
<p>This is arguably the main pain-point with dependent types. Proving that one constraint implies another can be tiresome and can clutter up code significantly. Refinement type systems solve this through restricting constraints to those that can be dispatched with an SMT solver, but this is often limiting. WTy2 attempts to provide some of the ergonomics of refinement types without the restrictions through the ability to write and use implicit <code>proof</code>s.</p>
<p><sup class="footnote-reference"><a href="#note">1</a></sup> As a side note, on the current Idris2 version (0.6.0), if <code>x &lt;= 3</code> is replaced with <code>x &lt; 4</code>, the example breaks, with the compiler protesting that case <code>foo (Mk (S (S (S (S _)))) _)</code> is not covered. I suspect this is a bug.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="proofs"><a class="header" href="#proofs">Proofs</a></h1>
<p>In many dependently typed language, an unfortunate side effect of needing to translate between different constraints is that code must be cluttered with calls to functions that do effectively nothing except prove that some constraint implies another.</p>
<p>WTy2 attempts to separate out these &quot;proof&quot; functions from the code that requires them through the mechanism of implicit <code>proof</code>s.</p>
<h2 id="syntax"><a class="header" href="#syntax">Syntax</a></h2>
<p>The <code>proof</code> keyword can be written before a variable definition, with the name of the variable optionally elided. Named <code>proof</code>s can be called just like normal functions.</p>
<p>Variables annotated as <code>proof</code>s must be functions that return something of type <code>Proof(c)</code> for some <code>c: Constraint</code>.</p>
<h2 id="semantics"><a class="header" href="#semantics">Semantics</a></h2>
<p>During WTy2 typechecking, all constraints which could not be satisfied are collected (along with their associated local typing contexts). For each of these constraints, we iterate through every in-scope <code>proof</code> and attempt to apply it (i.e: trying to match result/head of the <code>proof</code>s up with the desired constraint, via a similar mechanism to how superclass constraints are applied).</p>
<p>If introducing a call to the proof function immediately before the offending expression (concretely, for expression <code>e</code> and proof function <code>p</code>, replacing <code>e</code> with <code>do { Refl := p(...); e }</code>) allows the expression to typecheck, then we are done, and move on to the next stuck constraint. If there is still an error, there might still be a more suitable <code>proof</code> in scope and so we undo changes (revert to just <code>e</code>), and try to apply the next <code>proof</code>. If all in-scope <code>proof</code>s are exhausted, then the type error is outputted as normal.</p>
<p>Importantly, inserted <code>proof</code>s are limited to single function calls. If there is a proof that <code>A =&gt; B</code> and a proof that <code>B =&gt; C</code>, and a proof of <code>A =&gt; C</code> is required, the programmer must explicitly write a new proof of <code>A =&gt; C</code>. This is to prevent typechecking from looping.</p>
<pre><code class="language-WTy2">proof(Proof(A)): Proof(B)

proof(Proof(B)): Proof(C)

proof(Proof(A)): Proof(C) = do {
    _: Proof(B) = QED;
    QED
}
</code></pre>
<h2 id="design-note-transitive-closure-of-proofs"><a class="header" href="#design-note-transitive-closure-of-proofs">Design Note: Transitive Closure of Proofs</a></h2>
<p>While needing to write transitive proofs might seem slightly painful, note it is NOT intended that every single possible valid proof function is written. First of all, this is likely impossible (for the same reason typechecking would loop: infinite valid proofs can be obtained while starting from a finite number), but also, it is unnecessary! Why prove anything that isn't helpful?</p>
<p>Instead, it is hoped that the WTy2 programmer writes code assuming all obvious implications are known to the typechecker, and then if a type error is encountered, the programmer writes the <code>proof</code> that fixes that specific error. The benefit is that now all future times that same error would appear, the in-scope <code>proof</code> is implicitly reused.</p>
<h2 id="design-note-provisional-definitions"><a class="header" href="#design-note-provisional-definitions">Design Note: Provisional Definitions</a></h2>
<p>Idris has a feature with a similar goal (that of splitting proofs and code relying on them) known as &quot;Provisional Definitions&quot; https://docs.idris-lang.org/en/latest/tutorial/provisional.html. The main disadvantage is that you do not get the reuse of proofs that comes from WTy2 (i.e: proofs must be specifically named based on the function they are required in).</p>
<p>The obvious benefit here is that the Idris compiler does not have to search through all possible implicit proofs, meaning the impact on typechecking performance is lessened. Right now, it is somewhat unclear how often implicit proofs will be able to be reused, but it is hoped that this will be a significant quality-of-life benefit for ordinary programs, perhaps even near the scale of much more heavyweight features, say, tactics (the convenience of not needing any explicit user-interaction when relying on properties like <code>m + n ~ n + m</code>, I think should not be understated).</p>
<h2 id="implementation-note-typechecking-performance"><a class="header" href="#implementation-note-typechecking-performance">Implementation Note: Typechecking Performance</a></h2>
<p>A naive implementation of the implicit proof searching algorithm will have a pretty devastating impact on typechecking performance. Hopefully some good method of pruning the search space can be found. It is also suggested that when <code>proof</code>s are successfully found, that information is cached somehow so on future compilation it does not need to be rediscovered.</p>
<p>Note the process of searching in-scope terms to find something that will allow the program to typecheck is not at all a new idea. Idris, for example, allows for writing explicit &quot;holes&quot; in programs https://docs.idris-lang.org/en/latest/elaboratorReflection/holes.html, where the compiler can automatically search for expressions that fit the desired type signature using functions labelled with <code>#hint</code> pragmas. Compared to this, WTy2 holes are relatively modest: the expressions are limited to single function calls.</p>
<h2 id="implementation-note-runtime-performance"><a class="header" href="#implementation-note-runtime-performance">Implementation Note: Runtime Performance</a></h2>
<p>WTy2 does not assume totality of functions. This includes proofs, and so it is entirely possible for a proof to typecheck, but then at runtime loop infinitely or crash.</p>
<p>For this reason, to preserve safety, running these proofs is unfortunately necessary. Execution these proofs can have severe performance impacts however (to the point of changing the time complexity of many algorithms). It is therefore suggested that WTy2 implementations allow compiling with an option that skips over calls to <code>proof</code>s, assuming totality. This has the consequence of ,aking infinite loops/runtime crashes in <code>proof</code>s undefined behaviour.</p>
<h2 id="modulesimports"><a class="header" href="#modulesimports">Modules/Imports</a></h2>
<p>It would be nice if importing <code>proof</code>s operated similarly to importing instances: just having them always be implicitly imported from modules.</p>
<p>However, it is unfortunately possible to write buggy/even malicious proofs (given they are not checked for totality) and so users should probably have some control over which <code>proof</code>s are brought into scope.</p>
<p>Importing a function and it's <code>proof</code>-y nature separately might be desirable, and so importing a named <code>proof</code> can be done as if it was an ordinary function, while importing it as an unnamed <code>proof</code> can be done with the specific syntax: <code>proof(proofFun1, proofFun2)</code>. All <code>proof</code>s in a module can be imported as <code>proof(..)</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dependent-types"><a class="header" href="#dependent-types">Dependent Types</a></h1>
<p>WTy2 features dependent record and function types.</p>
<p>TODO (should start with low level definitions of dependent cons/telescopes and dependent function arrow)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-3"><a class="header" href="#summary-3">Summary</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="low-level-semantics"><a class="header" href="#low-level-semantics">Low-level Semantics</a></h1>
<p>WTy2 is a programming language (read: language for writing programs). Programs are <em>usually</em> written with the intention of executing them on a computer, and so <em>some</em> thought should <em>probably</em> be put into how that might be achieved.</p>
<p>Original goals for WTy2 included having it be a suitable language for systems programming, with predictable compilation and <strong>blazing-fast</strong> performance. These are noble goals, but the reality of making a programming language is that there is only so much time and so I must admit: while I think (hope) that I have come up with novel and interesting ideas in the realm of abstraction, I have not been able to crack how to place those in a systems-programming-appropriate type system, and I do not believe I am likely to anytime soon.</p>
<p>Specifically, the state-of-the-art right now in this area seems generally to focus on linear/uniqueness typing, borrowing, monomorphisation and allowing unboxed types with suitable restrictions. Let's address each in turn:</p>
<ul>
<li>
<p><strong>Linearity/Uniqueness Typing</strong> - A very powerful type system feature, useful for expressing contracts with types (i.e: safe resource usage) on top of benefits for memory management implementation. However, it is also hard to combine with dependent types. Idris2 has managed the linearity half via QTT, but suffers from a lack of quantity polymorphism that requires code be duplicated to handle the different quantities, which is unnacceptable in an abstraction-driven language IMO.</p>
</li>
<li>
<p><strong>Borrowing</strong> - Linearity/uniqueness typing also has an additional problem: it is very restrictive (especially if it is the default). Lending a temporary reference (with the caller afterwards still free to drop or move the referenced value safely) becomes pretty necessary when using these typing features in practice. Unfortunately, these guarantees about how long referenced values live for are hard to track, requiring (lifetime) annotations and/or very restricted use.
Further, when references become pervasive in a language with subtyping, considerations must be made over whether that subtyping relation is coercive - effectively a decision between variance and efficient/flexible runtime representation. Both would be nice!</p>
</li>
<li>
<p><strong>Monomorphisation</strong> - Noticing how typeclasses, invented merely as a tool for abstraction in Haskell fit so perfectly with a low-level compilation strategy of compiling distinct versions of functions for each type is in my opinion the coolest thing <strong>by far</strong> about Rust. It's so clean that I spent quite a few months obsessed with the idea, looking at ways to enhance it <sup class="footnote-reference"><a href="#note">1</a></sup>.</p>
<p>Simultaneously, when types are viewed as sets of values, monomorphisation starts to look insane - it's entirely predicated on the idea that the number of sets of values considered by a program is vastly smaller than the number of values it deals with (for one, the number of those sets must be finite or your executable must become infinitely large). This simply isn't the case when subtyping, fancy-typing, let alone dependent typing are added to the mix. Plus as a dual to the predictability you get as a programmer, the compilation strategy reveals implementation details, requiring consideration on whether to suffer executable bloat or dynamic dispatch cost.</p>
</li>
<li>
<p><strong>Unboxed Types</strong> - I already rejected the duplication of code associated with linearity-without-polymorphism so that I similarly reject it in the context of (un)boxing should come as no surprise - and polymorphism over unboxed values relies on full monomorphisation. Further, giving control over exactly the representation of data inherently leaks implementation details (e.g: the decision of whether to pass by reference or value based on the size a type vs a pointer) to the programmer.</p>
<p>It is unfortunate that this is probably the feature least compatible with WTy2 and yet is one with potentially the highest impact (zero-cost FP via unboxed closures is very enticing). My hope is that a compiler doing extensive cross-module specialisation might be able to automatically unbox, but this is something that should be explored far down the line.</p>
</li>
</ul>
<p>I argue there are really two main aspects of implementation that these features are focussed on: memory management and runtime representation of values/dispatch strategy. For the former, WTy2 will take inspiration from Lean and Koka (similarly functional, pure, strict programming languages with rich type systems) and adopt a form of reference counting. What's especially nice about this approach is that it combines well with the lower-level type system features that might be added later (in-place updates for values with a refcount of one is just a runtime version of in-place updating of uniques, borrows can skip the refcount increment/decrement etc...). For the latter, in the best case specialising functions for specific sets of values is likely to be a significant optimisation, but the baseline strategy must support WTy2's infinitely large types, existential types etc... - a uniform runtime representation of values is required. See the dedicated section for the current design.</p>
<div class="footnote-definition" id="note"><sup class="footnote-definition-label">1</sup>
<p>For the curious reader, here were my two main ideas, which I still think are potentially cool, but simply do not fit with WTy2 whatsoever.</p>
</div>
<ul>
<li>Extend rust-style <code>impl</code> returns to allow returning values of potentially different types. This can be implemented by monomorphising all code following the call-site and statically dispatching at the <code>return</code> statement.</li>
<li>Allow variables to be generic (take a type parameter), allowing first-class higher-rank polymorphic functions, and also, perhaps more interestingly, super efficient heterogeneous unordered collections (data-oriented programming without the hassle).</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="runtime-representation"><a class="header" href="#runtime-representation">Runtime Representation</a></h1>
<p>Note that there is likely a <strong>ton</strong> of flexibility here, and I know very little about writing efficient language runtimes/low-level performance optimisation. The design I layout here is just a suggestion, that will probably be changed significantly over time <sup class="footnote-reference"><a href="#note">1</a></sup>.</p>
<p>WTy2 values are linked lists <sup class="footnote-reference"><a href="#note">1</a></sup> of tags, where each tag is 32-bits. The starting point for this idea is that these lists of tags are just the natural serialisations of the values (i.e: the <code>data</code> constructors). All tags are associated with some source-code identifier, and so to illustrate below, I will denote all tags as <code>T_&lt;Ident&gt;</code> where <code>&lt;Ident&gt;</code> is the associated identifier.</p>
<p>The first obvious issue with this is how to fit all the tags into 32-bits. For example, 32-bit integers alone would fill the space of tags. This is fixed by giving <code>datatype</code> declarations slightly unique semantics. A <code>datatype</code> defines one tag for the type, and then all variants are placed in a separate tag-space (and so are free to overlap with other tags in other <code>datatype</code>s).</p>
<p>To clarify, after the below two declarations:</p>
<pre><code class="language-WTy2">datatype Bool0 where
  True  : Bool0
  False : Bool0

data True0
data False0
type Bool1 = True1 | False1
</code></pre>
<p><code>x: Bool0 = True0</code> and <code>y: Bool1 = True1</code> (in the absense of other optimisations) will have differently lengthed tag lists at runtime - <code>x</code> will have a tag list of length two (<code>T_Bool0</code> and <code>T_True0</code>), while <code>y</code> will just be a single tag (<code>T_True1</code>).</p>
<p>In order to &quot;be not stupid&quot; <sup class="footnote-reference"><a href="#note">1</a></sup>, tags which are known to be fixed at compile time really should be elided. Achieving this is subtle though. Consider that WTy2 allows writing extensional proofs about functions like <code>for(x: Int) { foo(x) :: Int }</code> - does this mean we must elide the <code>T_Int0</code> tag from <code>foo</code>-returned values? Achieving this consistently in general is catastrophically undecidable (for the same reason WTy2 bounds the number of automatic proof insertions to one per goal constraint).</p>
<p>TODO - Come up with some tag-elision system that actually works, and supports aliasing (HARD).</p>
<div class="footnote-definition" id="note"><sup class="footnote-definition-label">1</sup>
<p>FYI, for a while, I really was aiming to avoid dictionary passing in ,pst cases by having longer tag lists which retain enough information to do instance selection, and dispatching based on those - I still am not sure if this is a good idea or not, but it felt much messier than what I currently outline here.
<sup class="footnote-reference"><a href="#note">1</a></sup>:
I think packing tags in memory might actually be possible if we added a special tag denoting a reference which could appear in any place in a value, but I need to think this over more.
In any case, this packing definitely would make implementation more complicated, and for an initial compiler I really want something easy and consistent, not necessarily fast.</p>
</div>
<div class="footnote-definition" id="note"><sup class="footnote-definition-label">1</sup>
<p>https://youtu.be/BcC3KScZ-yA?t=2150</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="core-language"><a class="header" href="#core-language">Core Language</a></h1>
<p>Implementing a typechecker and compiler for the entire WTy2 language at once is likely to prove somewhat challenging. Here, a design for an intermediate, typed core language (inspired by efforts on GHC) is outlined.</p>
<p>Core-Lang Constructs:</p>
<ul>
<li>Lambda case expressions (covers lambdas, matches and let bindings)</li>
<li>Telescopes: A single built-in datatype covering (dependent) tuples and lists</li>
<li>Dependent function arrows</li>
<li>Constraints (equality coercions, type membership, quantified constraints)</li>
<li>Data declarations</li>
<li>Type declarations, with associated methods and supertype constraints</li>
<li>Default instance declarations</li>
</ul>
<p>Desugaring:</p>
<ul>
<li>WTy2 core does not feature named tuples/records. These are instead desugared into telescopes like ordinary tuples and lists.</li>
<li>In WTy2 core, all function arrows are dependent, meaning a function that takes and returns an integer would be represented as <code>Int -&gt; { Int }</code></li>
</ul>
<p>Unanswered Questions:</p>
<ul>
<li>How to represent recursion? Could either use recursive binders or a dedicated fixpoint operator.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="specialisation"><a class="header" href="#specialisation">Specialisation</a></h1>
<p>WTy2 does NOT currently feature &quot;specialisation&quot; as a high-level language feature (à la Rust <sup class="footnote-reference"><a href="#note">1</a></sup>), being able to override typeclass instances for specific types. Instead, specialisation in the context of WTy2 refers to an optimisation strategy that is key to get highly polymorphic WTy2 programs to perform well<sup class="footnote-reference"><a href="#note">1</a></sup>.</p>
<p>Specialisation can be thought of a bit like a &quot;lite&quot; version of monomorphisation. Types can be arbitrarily large in WTy2, so full monomorphisation as a compilation strategy is infeasible; however, where possible, compiling separate versions of functions for specific argument values (or sets of argument values) and dispatching to those specialised versions can get most of the benefits (the main downside being the compiler now has to decide on a strategy for deciding when to specialise).</p>
<p>Some possible heuristics for deciding when specialisation is a good idea might include:</p>
<ul>
<li>One of the function's arguments has a small set of inhabiting values. For example, if a function takes a <code>Bool</code> argument, specialisations for when the <code>Bool</code> is <code>True</code> and <code>False</code> are probably a good idea.</li>
<li>A function is explicitly called somewhere in the program with an argument of more constrained type than the function could accept. For example, if a function takes an arbitrary <code>Num</code> and is called somewhere with an <code>Int</code>, a specialisation for <code>Int</code>s should probably be generated. If the function is called with a constant <code>23</code>, then a specialisation for this exact integer could be generated (effectively constant-folding).</li>
<li>Note after one function is specialised, function calls in that function's body may now also become candidates for specialisation by the rule above. This transitive specialisation is very powerful, as it can eliminate what might otherwise be a large number of repeated matches.</li>
</ul>
<p>Specialisation is similar to inlining, but generated specialised code can be reused, reducing executable bloat. Prioritising specialisation over inlining seems like a reasonable goal.</p>
<h2 id="dispatching-to-specialised-functions"><a class="header" href="#dispatching-to-specialised-functions">Dispatching to Specialised Functions</a></h2>
<p>Dispatching to specialised functions at runtime rather than compile time would greatly increase the power of this optimisation. i.e: suppose there is a function <code>foo : impl(Num) -&gt; Bool</code> with a much faster specialisation for <code>n ~ Int</code>. We would like to ensure that even code like <code>x: Int = 0; y: Num = x; z = foo(y);</code> uses the specialiased version of <code>foo</code>, using the type information (in the form of variant tags) that is kept around at runtime to dispatch appropriately (assuming the savings from running the specialised version are worth it over the cost of dispatching appropriately).</p>
<p>Exactly how feasible this is will likely have to be reassessed after the design for open types/instances is finalised, but this potentially could be implemented very simply as just a compiler pass which adds seemingly redundant pattern matches before various function calls that appear to be good candidates for specialisation <sup class="footnote-reference"><a href="#note">1</a></sup>.</p>
<div class="footnote-definition" id="note"><sup class="footnote-definition-label">1</sup>
<p>The writer of the specification personally considers this form of specialisation (sometimes called ad-hoc polymorphism) as a misfeature and so would be hesitent to work on it, even if there was a feasible implementation strategy for it in WTy2.
<sup class="footnote-reference"><a href="#note">1</a></sup>: À la Haskell - https://wiki.haskell.org/Inlining_and_Specialisation#What_is_specialisation.3F
<sup class="footnote-reference"><a href="#note">1</a></sup>: Of course, pattern matches are only possible on values of closed types in the source language, but when it comes to implementation, all values could (and likely will) be fully tagged.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="summary-4"><a class="header" href="#summary-4">Summary</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="soundness"><a class="header" href="#soundness">Soundness</a></h1>
<p>WTy2 is a programming language with dependent types first and foremost, NOT a theorem prover.</p>
<p>In fact, viewed as a logic, WTy2 as it currently exists is highly inconsistent. It is trivial to prove bottom and from there anything. The only guarantee making this somewhat palatable is that these are all cases where the program will loop or crash at runtime. WTy2 (when programs are ran in debug mode without optimisations) will never actually create values of bottom type.</p>
<p>This is useful for programming (proving termination is tiresome and sometimes even impossible) but makes WTy2 effectively useless for theorem proving. In the far future if these holes were to be closed (likely opt-in with some sort of compiler pragma or flag, <code>safe</code>), then this would no longer be the case, and hence these holes are documented below:</p>
<h2 id="non-terminating-recursive-functions"><a class="header" href="#non-terminating-recursive-functions">Non-terminating Recursive Functions</a></h2>
<pre><code class="language-WTy2">foo() := foo()
</code></pre>
<h2 id="type-in-type"><a class="header" href="#type-in-type">Type in Type</a></h2>
<p>Similar to Haskell, WTy2 has the axiom <code>Type : Type</code>. Girard's paradox <sup class="footnote-reference"><a href="#note">1</a></sup> is almost certainly derivable from this.</p>
<h2 id="russels-paradox-directly"><a class="header" href="#russels-paradox-directly">Russel's Paradox, Directly</a></h2>
<p>WTy2's expressivity and subtyping allows for a much more direct encoding of Russel's paradox (treating types as sets).</p>
<pre><code class="language-WTy2">type Russel = (t: Type) &lt;&lt;= { t :: t =&gt; Bottom };
</code></pre>
<p>The additional danger here is that a suffiently advanced constraint solver could derive bottom entirely on it's own just from this definition being in-scope.</p>
<p>An informal sketch of how this might happen is outlined is below:</p>
<p>Constraints are written in similar syntax to WTy2 source, but we elide types of <code>for</code> bound variables, instead prefering to write them as implications.</p>
<pre><code class="language-WTy2CoSo"># From definition of Russel

[G1] for(t) { t :: Russel /\ t :: t =&gt; Bottom }
[G2] for(t) { (t :: t =&gt; Bottom) =&gt; t :: Russel }

[W1] Russel :: Russel

# Head of G2 matches, so instantiate t = Russel

[W2] Russel :: Russel =&gt; Bottom

# Need to show an implication, so assume LHS to reach RHS

[G3] Russel :: Russel
[W3] Bottom

# Head of G1 matches, so instantiate t = Russel

[W4] Russel :: Russel /\ Russel :: Russel

# Simplify

[W5] Russel :: Russel

# Solve with G3
</code></pre>
<p>And so we conclude by deriving <code>Russel :: Russel</code> (from which, we can trivially obtain <code>Bottom</code> via <code>G1</code>).</p>
<p>That this is a real danger is illustrated by how we can encode exactly problem with Haskell typeclasses:</p>
<pre><code class="language-hs">main :: IO ()
main = case veryBad of MkDict -&gt; no @(IO ())

class Bottom where
  no :: a

data Dict c where
  MkDict :: c =&gt; Dict c

data Set = Russel

type In :: Set -&gt; Set -&gt; Constraint
class ((a ~ b, In b Russel) =&gt; Bottom) =&gt; In a b

instance (In s s =&gt; Bottom) =&gt; In s Russel

bad :: Dict (In Russel Russel)
bad = MkDict

veryBad :: Dict Bottom
veryBad = case bad of MkDict -&gt; MkDict
</code></pre>
<p>Indeed, Haskell runtime loops when executing this program, despite there being no explicit recursion in the code<sup class="footnote-reference"><a href="#note">1</a></sup>.</p>
<p>IMO it is <em>pretty</em> important we avoid this. Mathematicians might argue the cause of the problem here is the typeclass declaration itself, but ruling it out would require a drastic reduction of WTy2's expressivity (e.g: removing an entire feature, like the <code>(&lt;&lt;=)</code> operator) or adding type universes.</p>
<p>Luckily, there is a much easier fix: not giving the solver access to an implication-introduction rule. Instead implications should only be brought into scope via superclass constraints, instances and explicitly written <code>proof</code>s. We could of course write a <code>proof</code> of <code>Russel :: Russel =&gt; Bottom</code>, but that this would loop at runtime is fine - we at least have source code we can point to in a stack trace (<code>proof</code>s are not totality-checked in WTy2).</p>
<p><sup class="footnote-reference"><a href="#note">1</a></sup> See http://liamoc.net/posts/2015-09-10-girards-paradox.html for a nice walkthrough of how to derive this in Agda.</p>
<p><sup class="footnote-reference"><a href="#note">1</a></sup> Though do note that the loop in Haskell can be encoded much more simply (and arguably arises from using superclass constraints when checking instances):</p>
<pre><code class="language-hs">class (ImpliesBottom =&gt; Bottom) =&gt; ImpliesBottom

instance ImpliesBottom
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="syntax-debates"><a class="header" href="#syntax-debates">Syntax Debates</a></h1>
<p><a href="https://wiki.haskell.org/Wadler&#x27;s_Law">https://wiki.haskell.org/Wadler's_Law</a></p>
<p>Syntax is hard, and discussions about it tends to go nowhere...</p>
<p>...so let's discuss syntax!</p>
<h2 id="enforced-capitalisation-convention"><a class="header" href="#enforced-capitalisation-convention">Enforced Capitalisation Convention</a></h2>
<p>In functional languages, it is easy to have an ambiguity with irrefutable pattern matches vs variable bindings. Consider in Haskell:</p>
<pre><code class="language-hs">foo = ...
  where
    {- Function or Constructor -} i = ...
</code></pre>
<p>Haskell gets around the ambiguity here by enforcing a simple capitalisation convention: constructors must start with a capital letter, and variables must start with a lowercase one.</p>
<pre><code class="language-hs">foo = ...
  where
    Bar i = ... -- Pattern match
    bar i = ... -- Local function definition
</code></pre>
<p>As long as, the language allows nullary data constructors data constructors this does not just apply to functions, and the ambiguity in WTy2 specifically is even more prevalent, given the rule that <code>f: t -&gt; u</code> can be written as <code>f(t): u</code>.</p>
<p>One obvious solution is to copy Haskell's homework: data constructors are capitalised and variables are not. This rule fits well with WTy2's style in general: types should be capitalised, and this makes sense because types, like data constructors, are matchable.</p>
<p>However, there are downsides. The most compelling from my perspective is how non-latin alphabets do not necessarily contain capital letters. I do not believe this is quite as significant of an issue as sometimes presented (a convention for code written in those alphabets could easily be created where data constructors/types must start with a latin-alphabet capital letter, say <code>M</code> for <code>matchable</code>) but even so, it is not ideal.</p>
<p>The alternative is to use some dedicated keyword/symbol to disambuate. Perhaps <code>def</code> prefixing all variable bindings or <code>match</code> prefixing all irrefutable pattern matches.</p>
<p>Using <code>def</code> keyword on functions</p>
<pre><code class="language-WTy2">def takesFunctionAndMatches(def foo(Int): Int, MkFoo(x): Foo) := do {
    def bar(y: Int) := foo(y);
    MkBar(z) := x;
}
</code></pre>
<p>Using <code>match</code> keyword on matches</p>
<pre><code>takesFunctionAndMatches(foo(Int): Int, match MkFoo(x): Foo) := do {
    bar(y: Int) := foo(y);
    match MkBar(z) := x;
}
</code></pre>
<p>Neither alternative feels great though coming from Haskell. There is no reward for following the capitalisation convention! My current plan is therefore a compromise: capitalised = assume match, lowercase = assume variable, but the programmer can also use either keyword to override. This might be an overkill solution, but it seems promising (and actually quite easy to parse!).</p>
<h2 id="bindingconstraint-operators"><a class="header" href="#bindingconstraint-operators">Binding/Constraint Operators</a></h2>
<p>Currently, I am liking:</p>
<div class="table-wrapper"><table><thead><tr><th>Binding</th><th>Constraint</th><th>Meaning</th></tr></thead><tbody>
<tr><td><code>x : t</code></td><td><code>x :: t</code></td><td><code>x</code> has type <code>t</code></td></tr>
<tr><td><code>t &lt;: u</code></td><td><code>t &lt;| </code></td><td><code>t</code> is a subtype of <code>u</code></td></tr>
<tr><td><code>x : 'y</code></td><td><code>x ~ y</code></td><td><code>x</code> and <code>y</code> are propositionally equal</td></tr>
</tbody></table>
</div>
<p>But there are a few possible alternatives and questions:</p>
<ul>
<li>Use keywords/infix functions instead of operators. E.g: <code>x is t</code>/<code>x in t</code> instead of <code>x :: t</code>.</li>
<li>Make the common pattern for constraint (except for <code>(~)</code>) be to add a second colon. E.g: <code>(&lt;::)</code> instead of <code>(&lt;|)</code>.</li>
<li>Add a dedicated binding operator for <code>(~)</code>, such as <code>(~:)</code>.</li>
<li>Instead of <code>(::)</code>, all types could implement <code>Any -&gt; Constraint</code> so instead of <code>x :: Int</code> you would write <code>Int(x)</code> (a bit Verse-like).</li>
<li>With <code>(:)</code>, <code>(::)</code>, and <code>(&lt;:)</code> taken, what should cons be? <code>(:&gt;)</code> could very easily be misinterpreted as a flipped version of <code>(&lt;:)</code>. Perhaps <code>(:;)</code> or <code>(:.)</code>?</li>
</ul>
<h2 id="implicit-braces"><a class="header" href="#implicit-braces">Implicit Braces</a></h2>
<p>WTy2 contains a few built-in dependent type operators (<code>(-&gt;)</code>, <code>(~&gt;)</code>) which automatically add braces to the RHS if the type expression does not type-check without. The advantage is obvious: cleaner syntax. All non-dependent functions requiring braces around the result type (e.g: <code>Int -&gt; { Int }</code>) (or using a different arrow) is ugly.</p>
<p>That said, this is clearly a special case, and special cases generally do not lead to a cleaner and easier-to-learn language. It might be worth considering if this implicit lambda-abstraction functionality is something that should be possible to opt into with other operators.</p>
<h2 id="unicode"><a class="header" href="#unicode">Unicode</a></h2>
<p>TODO</p>
<ul>
<li><code>∀</code> should be parsed as a letter to allow <code>∀ := for</code>.</li>
</ul>
<h2 id="lambdapattern-match-syntax"><a class="header" href="#lambdapattern-match-syntax">Lambda/Pattern Match Syntax</a></h2>
<p>Currently, for lambdas that bind variables, I like the look of the following syntax: <code>{ \Pat -&gt; ...}</code> for irrefutable patterns and <code>{ | Pat1 -&gt; ..., | Pat2 -&gt; ... }</code> for lambda-case expressions.</p>
<p>However, this does overload the meaning of <code>-&gt;</code> somewhat. Lambda-calculus gives us an alternative separator <code>.</code> as in <code>{ \Pat. ... }</code> which I don't hate, but I find <code>{ | Pat1. ..., | Pat2. ... }</code> very ugly. <code>{ \Pat1. ..., \Pat2. ... }</code> is better but now no longer really looks like a pattern match.</p>
<p>Yet another alternative is to use an arrow with a bar <code>|-&gt;</code>. This is justified via numerous FP papers which use the LaTeX equivalent of this symbol, but of course transliterated into ASCII, it does look somewhat ugly.</p>
<h2 id="such-that-operator"><a class="header" href="#such-that-operator">&quot;Such That&quot; Operator</a></h2>
<p>There appears to not really be a standard operator for &quot;such that&quot; in mathematics (except in set comprehensions, but <code>(:)</code> and <code>(|)</code> are already taken), and the most common, (<code>∋</code>)<sup class="footnote-reference"><a href="#note">1</a></sup>, does not have a reasonable ASCII approximation (at least that I can think of).</p>
<p><code>(&lt;&lt;=)</code> I think has some advantages in that it is very clearly not symmetrical (IMO symmetrical-looking glyphs as operators should really only identify associative, if not commutative operations) and it is vaguely reminiscent of <code>(=&gt;)</code> which in Haskell is used to represent the curried version of a similar concept. On the other hand, it (surprisingly) doesn't appear to have a unicode equivalent (there are double-headed arrows, and double-lined arrows, but apparently no double-headed-double-lined arrows...).</p>
<p>On the other hand, a very common operator being three-characters long is a bit unfortunate. <code>(-&lt;)</code> is IMO quite aesthetically nice and I do also quite like <code>($)</code> given how (if you squint) it looks a bit like an <code>S</code> and a <code>T</code> overlaid.</p>
<div class="footnote-definition" id="note"><sup class="footnote-definition-label">1</sup>
<p>A few examples of various &quot;such that&quot; operators can be found at https://math.stackexchange.com/a/2777911</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="type-aware-allocators"><a class="header" href="#type-aware-allocators">Type Aware Allocators</a></h1>
<p>A goal of WTy2 is to allow for good performance (especially with regards to memory locality) without much additional work on the part of the programmer/enforcing closed-world assumptions on written code.</p>
<p>A major part of this is the concept of a type-aware-allocator. WTy2 makes extensive use of allocators (array based and recursive data structures in WTy2 should ideally be generic over the allocation scheme) so by providing tools to create good ones, almost all data structures should benefit.</p>
<p>As an example for the sort of properties we would like to achieve, suppose our program had a large list of <code>Int</code>s, this was then upcasted into a list of <code>Num</code>s and then many other opaque <code>Num</code>s got added to the list. We then calculate a total sum (note that this operation does not care about the order in which we iterate over the values). Ideally therefore (for cache and memory locality reasons) we should somehow keep all the <code>Int</code>s in their own region of memory and sum these first.</p>
<p>The rules for performing specialisation with these allocators should use similar (perhaps the same) rules as ordinary function specialisation. i.e: a good heuristic is if we allocate any value with known concrete type, we should specialise for that type.</p>
<p>It would be ideal if WTy2 could provide some sort of language interface to create custom type-aware alloactors. I do not currently have a good model for how to design this. Difficulties I can currently forsee include prevent the number of specialisations from being observable (to prevent UB - the compiler is free to specialise as much or as little as it wants), and more generally just challenges of writing low-level mutability-based code in a pure functional language.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="recursive-data-types"><a class="header" href="#recursive-data-types">Recursive Data Types</a></h1>
<p>Elsewhere in this spec (I may go back and fix it up later), I have been relatively loose with defining types like:</p>
<pre><code class="language-WTy2">data Cons(head: t, tail: List(t))
data Nil

type List(t: Type) = [head: t, tail: List(t)]
                     Is(Cons(head, tail))
                   | Is(Nil)
</code></pre>
<p>Unfortunately, there is a bit of an issue with values of this type - they have unbounded size! Specifically, if a function takes a <code>List(Int)</code>, the actual list it could receive when called could contain any number of <code>Cons</code> nodes.</p>
<p>Furthermore, it is not clear how to implement variance for this type. If we have a <code>List(Int)</code>, then ideally at each node we would not store any information informing us that the item is indeed an <code>Int</code> (we can know that it could be nothing else from the type signature). However, we would like to be able to pass this into functions accepting say <code>List(Num)</code>. This would seemingly require creating an entirely new list with the <code>Int</code> tag attached to every node.</p>
<p>One potential solution is to simply not use recursive data types. An array list-based data structure would help to avoid these problems and would also provide great memory locality. In functional languages like Haskell and Closure, however, the utility of being able to create large linked structures that utilise sharing cannot really be understated. WTy2 should be able to achieve something similar.</p>
<p>The solution is references, but with perhaps a slightly different flavour to what you might imagine coming from languages like Rust.</p>
<pre><code class="language-WTy2">data Cons[r: Ref](head: t, tail: List(r, t))
data Nil
type List(r: Ref, t: Type) = r(
    [head, tail: List(r, t)] Is(Cons(head, tail))
                           | Is(Nil)
    )
</code></pre>
<p>The main interesting thing about this definition is that <code>r</code>, the type variable that will be instantiated to some sort of reference that will break up the infinite structure, is generic. We could instantiate <code>r</code> to some owning reference type like <code>Box</code> and get a definition similar to what we would achieve in Rust, but we can also do better.</p>
<p>The problem with <code>Box</code> or any other global allocator is poor memory locality. If the elements are added to the list randomly over time, then they will be placed in effectively random locations in memory. What we would like is for every element of the same list (not just same type!) to be placed in more-or-less the same location (note this idea is similar to that of arenas in Rust).</p>
<pre><code class="language-WTy2">type Alloc = ...
type RefTo(a: Alloc, t: Type) = ...

// Get the allocator of a reference
allocOf[a: Alloc, t: Type](r: RefTo(a, t)): Alloc &lt;== { it ~ a }

// Would be a method of the 'Alloc' type
alloc(a: Alloc, t: Type): RefTo(a, t)

// Create a new allocator and allocate an expression using it
new[t](x: t): [a] RefTo(a, t)

// Function application, but wrap in the allocator at the end
build[a: Alloc, t: Type](x: RefTo(a, t), f: RefTo(a, t) -&gt; t)
    : RefTo(a, t) = alloc(allocOf(x), f(x))

// We take advantage of partial signatures to not need to specify the allocator
// in the signatures of 'x' or 'y'
x: List(t=Int) = new(Nil)
y: List(t=Int) = build(x) { Cons(3, it) }


// Alternate style, arguably neater but requires some extra busywork

type ConsLike(r, t) = [head: t, tail: List(r, t)] Is(Cons(head, tail))

// Would likely be a method of some type
// '(,..)' denotes partial application
// (i.e: will fill in the other arguments later)
allocOfCons[a: Alloc, r: RefTo(a,..), t: Type]
    (x: ConsLike(r, t)): Alloc &lt;== { it ~ a  }
    = match(x) case(Cons(_, tail)) -&gt; allocOf(tail)


altBuild[a: Alloc, r: RefTo(a,..), t: Type]
    (x: ConsLike(r, t)): List(r, t)
    = alloc(allocOfCons(x), x)


z: List(t=Int) = altBuild(Cons(3, x))
</code></pre>
<p>There are some interesting consequences of enforcing code like this. For example, if you have two different lists, potentially created with different allocators, the elements from one allocator must be all copied into the other. Because of this, it is recommended that if an algorithm involves a lot of merging of linked data structures, there a single allocator is created at the start and all sub-structures are built up with it.</p>
<p>Note that having the allocator responsible for storing all nodes also helps with the variance problem as mentioned above. Allocators in WTy2 must provide a way of recovering full type information for every value that is stored by them, but to ensure memory is not wasted, a good allocator would store elements with common type prefixes together and avoid duplicating said prefix. The exact mechanism for how these prefixes are represented is WIP and would be dependent on the allocator in question, but one could imagine, for instance, a binary tree which is traversed based on the reference and stores the common prefixes at the leaves.</p>
<p>The main downside is arguably the unfortunate amount of syntactic noise (for instance, compared to similar linked data structures in Haskell). Still, this is somewhat to be expected in a more low-level programming language - with the clutter comes flexibility.</p>
<p>A very nice side-effect is that in simple cases, as <code>r</code> is not restricted to be matchable (it uses the ordinary function arrow), references can be omitted for known finitely sized structures.</p>
<pre><code class="language-WTy2">x: List(r={it}, t=Int) = Cons(1, Cons(2, Cons(3, Nil)))
</code></pre>
<p>Note this works because the type of <code>x</code> is elaborated with the constraint <code>x ~ Cons(1, Cons(2, Cons(3, Nil)))</code> which fixes the size of <code>x</code>.</p>
<p>In theory, this means lists with constraints that ensure finite length should also be allowed. In practise, compilers may want to try and detect these cases by iterating through potential inhabiting values. If iterating through all potential inhabiting values takes too long, it is likely that the structure is large enough that it would benefit from being heap allocated anyway. Perhaps it could be made possible (via dependent types) to allow the programmer to write proofs that a constraint implies that the size of the type is bounded.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="theme/ligature_toggle.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
